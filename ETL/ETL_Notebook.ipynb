{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Project\n",
    "### ***NFL Draft Analysis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create secrets.py file with username and password to pgadmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import username and password from secrets.py file\n",
    "from secrets import username, password, database_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the data from Wikipedia and  www.pro-football-reference.com. \n",
    "* Note: Since we are scraping data from tables we are using pandas otherwise we were going to need to use BeatifulSoup and Splinter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Combine Info from 2016-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign Combine URL's to variable\n",
    "combine_url_2016 =  'https://www.pro-football-reference.com/draft/2016-combine.htm'\n",
    "combine_url_2017 = 'https://www.pro-football-reference.com/draft/2017-combine.htm'\n",
    "combine_url_2018 = 'https://www.pro-football-reference.com/draft/2018-combine.htm'\n",
    "combine_url_2019 = 'https://www.pro-football-reference.com/draft/2019-combine.htm'\n",
    "combine_url_2020 = 'https://www.pro-football-reference.com/draft/2020-combine.htm#combine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Pandas to read in html tables from combine URL's\n",
    "combine_2016 = pd.read_html(combine_url_2016)\n",
    "combine_2017 = pd.read_html(combine_url_2017)\n",
    "combine_2018 = pd.read_html(combine_url_2018)\n",
    "combine_2019 = pd.read_html(combine_url_2019)\n",
    "combine_2020 = pd.read_html(combine_url_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the 0th HTML Table to get the necessary combine info\n",
    "combine_df_2016 = combine_2016[0]\n",
    "combine_df_2017 = combine_2017[0]\n",
    "combine_df_2018 = combine_2018[0]\n",
    "combine_df_2019 = combine_2019[0]\n",
    "combine_df_2020 = combine_2020[0]\n",
    "#Preiew the 2016 Combine DF - Combine Extraction Complete!\n",
    "combine_df_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Draft Info from 2016-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign Draft URL's to variable\n",
    "draft_url_2016 = 'https://en.wikipedia.org/wiki/2016_NFL_Draft'\n",
    "draft_url_2017 = 'https://en.wikipedia.org/wiki/2017_NFL_Draft'\n",
    "draft_url_2018 = 'https://en.wikipedia.org/wiki/2018_NFL_Draft'\n",
    "draft_url_2019 = 'https://en.wikipedia.org/wiki/2019_NFL_Draft'\n",
    "draft_url_2020 = 'https://en.wikipedia.org/wiki/2020_NFL_Draft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Pandas to read in html tables from draft URL's\n",
    "draft_2016 = pd.read_html(draft_url_2016)\n",
    "draft_2017 = pd.read_html(draft_url_2017)\n",
    "draft_2018 = pd.read_html(draft_url_2018)\n",
    "draft_2019 = pd.read_html(draft_url_2019)\n",
    "draft_2020 = pd.read_html(draft_url_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the 4th HTML Table to get the necessary combine info\n",
    "draft_df_2016 = draft_2016[4]\n",
    "draft_df_2017 = draft_2017[4]\n",
    "draft_df_2018 = draft_2018[4]\n",
    "draft_df_2019 = draft_2019[4]\n",
    "draft_df_2020 = draft_2020[4]\n",
    "#Preview the 2016 Draft DF - Draft Extraction Complete!\n",
    "draft_df_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate and Clean Up Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add year to each combine DF\n",
    "combine_df_2016['year']='2016'\n",
    "combine_df_2017['year']='2017'\n",
    "combine_df_2018['year']='2018'\n",
    "combine_df_2019['year']='2019'\n",
    "combine_df_2020['year']='2020'\n",
    "#Add year to each draft DF\n",
    "draft_df_2016['year']='2016'\n",
    "draft_df_2017['year']='2017'\n",
    "draft_df_2018['year']='2018'\n",
    "draft_df_2019['year']='2019'\n",
    "draft_df_2020['year']='2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview 2016 Combine Data with Year Column Added\n",
    "combine_df_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine 2016-2020 Combine DF's into 1 DF\n",
    "combine_frames = [combine_df_2016, combine_df_2017, combine_df_2018, combine_df_2019, combine_df_2020]\n",
    "combined_combine_df = pd.concat(combine_frames)\n",
    "\n",
    "#Drop and Rename Columns\n",
    "combined_combine_df = combined_combine_df.drop(columns = ['Drafted (tm/rnd/yr)', 'College'])\n",
    "combined_combine_df = combined_combine_df.rename(columns = {'Player': 'name', 'Ht': 'Height', 'Wt': 'Weight', '40yd': 'Forty_Yard',\n",
    "                                                            '3Cone': 'Three_Cone', 'year': 'Year', 'Broad Jump': 'Broad_Jump',\n",
    "                                                           'Pos': 'position'})\n",
    "#Preview the Combined combine DF\n",
    "combined_combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Height to Float\n",
    "def fix(string):\n",
    "    try:\n",
    "        feet = int(string.split('-')[0])\n",
    "    \n",
    "        inches = int(string.split('-')[1])\n",
    "\n",
    "    #thats for feet and inches\n",
    "        return feet * 12 + inches\n",
    "    except:\n",
    "        return string\n",
    "    \n",
    "combined_combine_df['Height'] = combined_combine_df['Height'].apply(fix)\n",
    "#Preview the Complete total combine DF - Combine DF Cleanup Complete!\n",
    "combined_combine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_table_df = combined_combine_df.drop(columns = ['position', 'School', 'Height', 'Weight', 'Year'])\n",
    "combine_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate and Clean Up Draft Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview the 2016 Draft DF with year column added\n",
    "draft_df_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine 2016-2020 Draft DF's into 1 DF\n",
    "draft_frames = [draft_df_2016, draft_df_2017, draft_df_2018, draft_df_2019, draft_df_2020]\n",
    "combined_draft_df = pd.concat(draft_frames)\n",
    "#Drop and Rename Draft DF Columns\n",
    "combined_draft_df = combined_draft_df.drop(columns = ['Notes', 'Unnamed: 0',])\n",
    "combined_draft_df = combined_draft_df.rename(columns = {\"Player\": \"name\", \"NFL team\": \"NFL_Team\", \"Pos.\": \"position\", \n",
    "                                                        \"College\":\"School\", \"Conf.\": \"Conf\", \n",
    "                                                        \"Rnd.\": \"Round\", \"Pick No.\": \"Pick_No\", \"year\": \"Year\"})\n",
    "#Preview the combined draft DF\n",
    "combined_draft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = combined_draft_df.drop(columns = ['Round','Pick_No', 'position','School','Conf','Year'])\n",
    "teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_table_df = combined_draft_df.drop(columns = ['NFL_Team', 'position','School','Conf','Year'])\n",
    "draft_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info_frames = [combined_combine_df, combined_draft_df]\n",
    "#Combine both player dataframes\n",
    "\n",
    "combined_info_df = pd.concat(info_frames)\n",
    "#Drop duplicate players in combined_player_df\n",
    "info_df = combined_info_df.drop_duplicates(subset='name', keep='first', ignore_index=True)\n",
    "# Drop columns we are not using for the info table\n",
    "info_df = info_df.drop(columns = ['Forty_Yard','Vertical','Bench','Broad_Jump','Three_Cone','Shuttle',\n",
    "'Round','Pick_No','NFL_Team',])\n",
    "#-----------------------------------------------------------------\n",
    "# Define School DF\n",
    "schools_df = info_df.drop(columns = ['position', 'Height','Weight', 'Year'])\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "#Drop School Column\n",
    "info_df = info_df.drop(columns = ['School','Conf'])\n",
    "\n",
    "\n",
    "#Preview combined_player_df\n",
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### School DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Need to get one single dataframe of just the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_table_df = pd.DataFrame(info_df['name'])\n",
    "players_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataframes before loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframes before loading\n",
    "\n",
    "# players_table_df\n",
    "# info_df\n",
    "# teams_df\n",
    "# combine_table_df\n",
    "# draft_table_df\n",
    "\n",
    "players_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_table_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to local database\n",
    "rds_connection_string = f'{username}:{password}@localhost:5432/{database_name}'\n",
    "engine = create_engine(f'{username}+psycopg2://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the tables names to make sure where are we posting\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the keys of the tables to make sure everything match exactly.\n",
    "#if match EXACTLY WITH THE SAME NAME FOR COLUMNS IN THE DATAFRAME AND IN THE TABLE KEYS GO TO NEXT CELL.\n",
    "combine_table=engine.execute('SELECT * FROM combine')\n",
    "players_table=engine.execute('SELECT * FROM player')\n",
    "draft_table=engine.execute('SELECT * FROM draft')\n",
    "print(combine_table.keys())\n",
    "print(players_table.keys())\n",
    "print(draft_table.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# players_table_df\n",
    "# info_df\n",
    "# teams_df\n",
    "# combine_table_df\n",
    "# draft_table_df\n",
    "# schools_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using pandas. name stands for table name, change it if neccesary.\n",
    "players_table_df.to_sql(name='player', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the data has been Load. Check table name. Create a dataframe to get player_id to the other dataframes\n",
    "player_id_df=pd.read_sql_query('select * from player', con=engine)\n",
    "player_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table_df = pd.merge(info_df, player_id_df, how = 'inner', on = 'name')\n",
    "info_table_df = info_table_df.drop(columns = 'name')\n",
    "\n",
    "## convert Height and Weight to numeric\n",
    "info_table_df['Height'] = pd.to_numeric(info_table_df['Height'], errors='coerce')\n",
    "#com_df_final['Ht'].convert_dtypes(infer_objects=True, convert_string=True)\n",
    "info_table_df['Weight'] = pd.to_numeric(info_table_df['Weight'], errors='coerce')\n",
    "info_table_df['Year'] = pd.to_numeric(info_table_df['Year'], errors='coerce')\n",
    "info_table_df['position'] = info_table_df['position'].convert_dtypes(infer_objects=True, convert_string=True)\n",
    "\n",
    "info_table_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_table_df = pd.merge(teams_df, player_id_df, how = 'inner', on = 'name')\n",
    "teams_table_df = teams_table_df.drop(columns = 'name')\n",
    "teams_table_df['NFL_Team'] = teams_table_df['NFL_Team'].convert_dtypes(infer_objects=True, convert_string=True)\n",
    "teams_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df_final = pd.merge(combine_table_df, player_id_df, how = 'inner', on = 'name')\n",
    "combine_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df_final = pd.merge(combine_table_df, player_id_df, how = 'inner', on = 'name')\n",
    "combine_df_final = combine_df_final.drop(columns = 'name')\n",
    "\n",
    "# Convert\n",
    "##### The columns names needs to be changed\n",
    "combine_df_final['Forty_Yard'] = pd.to_numeric(combine_df_final['Forty_Yard'], errors='coerce')\n",
    "combine_df_final['Bench'] = pd.to_numeric(combine_df_final['Bench'], errors='coerce')\n",
    "combine_df_final['Vertical'] = pd.to_numeric(combine_df_final['Vertical'], errors='coerce')\n",
    "combine_df_final['Broad_Jump'] = pd.to_numeric(combine_df_final['Broad_Jump'], errors='coerce')\n",
    "combine_df_final['Three_Cone'] = pd.to_numeric(combine_df_final['Three_Cone'], errors='coerce')\n",
    "combine_df_final['Shuttle'] = pd.to_numeric(combine_df_final['Shuttle'], errors='coerce')\n",
    "# Get the info of the dataframe\n",
    "combine_df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with draft dataframe to get the serial id.\n",
    "draft_df_final = pd.merge(draft_table_df, player_id_df, how='inner', on='name')\n",
    "draft_df_final = draft_df_final.drop(columns = 'name')\n",
    "\n",
    "# # Convert types to fit in the database\n",
    " \n",
    "draft_df_final['Round'] = pd.to_numeric(draft_df_final['Round'], errors='coerce')\n",
    "draft_df_final['Pick_No'] = pd.to_numeric(draft_df_final['Pick_No'], errors='coerce')\n",
    "# draft_df_final['Pick_no'].convert_dtypes(infer_objects=True, convert_integer=True)\n",
    "\n",
    "\n",
    "draft_df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schools_df_final = pd.merge(schools_df, player_id_df, how='inner', on='name')\n",
    "\n",
    "schools_df_final = schools_df_final.drop(columns = 'name')\n",
    "\n",
    "schools_df_final['School'] = schools_df_final['School'].convert_dtypes(infer_objects=True, convert_string=True)\n",
    "schools_df_final['Conf'] = schools_df_final['Conf'].convert_dtypes(infer_objects=True, convert_string=True)\n",
    "\n",
    "schools_df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using pandas. name stands for table name, change it if neccesary.\n",
    "info_table_df.to_sql(name='info', con=engine, if_exists='append', index=False)\n",
    "teams_table_df.to_sql(name='teams', con=engine, if_exists='append', index=False)\n",
    "combine_df_final.to_sql(name='combine', con=engine, if_exists='append', index=False)\n",
    "draft_df_final.to_sql(name='draft', con=engine, if_exists='append', index=False)\n",
    "schools_df_final.to_sql(name='college', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database ready to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our Database\n",
    "schools = pd.read_sql_query('select * from college', con=engine)\n",
    "schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
